name: CD

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy to'
        required: true
        default: 'production'
        type: choice
        options:
          - production
          - staging
  push:
    branches:
      - main

# Cancel in-progress runs when a new run is triggered
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  AWS_REGION: eu-south-2
  ECR_REPOSITORY: hermes

jobs:
  build-and-push:
    name: Build and Push Docker Image
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build, tag, and push image to Amazon ECR
        id: build-image
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          docker buildx build \
            --platform linux/arm64 \
            --push \
            --tag $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG \
            --tag $ECR_REGISTRY/$ECR_REPOSITORY:latest \
            --cache-from type=registry,ref=$ECR_REGISTRY/$ECR_REPOSITORY:buildcache \
            --cache-to type=registry,ref=$ECR_REGISTRY/$ECR_REPOSITORY:buildcache,mode=max \
            .
          echo "image=$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG" >> $GITHUB_OUTPUT

    outputs:
      image: ${{ steps.build-image.outputs.image }}

  deploy-infrastructure:
    name: Deploy Infrastructure with Terraform
    runs-on: ubuntu-latest
    needs: build-and-push

    defaults:
      run:
        working-directory: terraform

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.0

      - name: Terraform Init
        run: terraform init

      - name: Terraform Plan
        id: plan
        run: |
          terraform plan \
            -var="database_url=${{ secrets.DATABASE_URL }}" \
            -var="secret_key_base=${{ secrets.SECRET_KEY_BASE }}" \
            -var="anthropic_api_key=${{ secrets.ANTHROPIC_API_KEY }}" \
            -var="certificate_arn=${{ secrets.ACM_CERTIFICATE_ARN }}" \
            -var="key_name=${{ secrets.EC2_KEY_NAME }}" \
            -var="phx_host=${{ secrets.PHX_HOST }}" \
            -out=tfplan

      - name: Terraform Apply
        if: github.ref == 'refs/heads/main'
        run: terraform apply -auto-approve tfplan

      - name: Get Terraform Outputs
        id: get-outputs
        run: |
          terraform output -json ec2_instance_ids > ec2_ids.json
          echo "ec2_ids=$(cat ec2_ids.json)" >> $GITHUB_OUTPUT
          echo "assets_bucket=$(terraform output -raw assets_bucket_name)" >> $GITHUB_OUTPUT
          echo "assets_url=$(terraform output -raw assets_url)" >> $GITHUB_OUTPUT
          echo "cloudfront_id=$(terraform output -raw cloudfront_distribution_id)" >> $GITHUB_OUTPUT

    outputs:
      ec2_ids: ${{ steps.get-outputs.outputs.ec2_ids }}
      assets_bucket: ${{ steps.get-outputs.outputs.assets_bucket }}
      assets_url: ${{ steps.get-outputs.outputs.assets_url }}
      cloudfront_id: ${{ steps.get-outputs.outputs.cloudfront_id }}

  upload-assets:
    name: Upload Static Assets to S3
    runs-on: ubuntu-latest
    needs: [build-and-push, deploy-infrastructure]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Extract static assets from Docker image
        env:
          IMAGE: ${{ needs.build-and-push.outputs.image }}
        run: |
          # Pull the ARM64 image (need to specify platform since runner is amd64)
          docker pull --platform linux/arm64 $IMAGE
          # Create a container from the image (don't run it)
          docker create --platform linux/arm64 --name assets-extractor $IMAGE
          # Copy static assets from the container
          docker cp assets-extractor:/app/lib/hermes-0.1.0/priv/static ./static
          # Remove the container
          docker rm assets-extractor
          # List extracted files
          ls -la ./static/

      - name: Upload assets to S3
        env:
          ASSETS_BUCKET: ${{ needs.deploy-infrastructure.outputs.assets_bucket }}
        run: |
          # Also copy static files from source (images, favicon, etc.)
          # These aren't included in the digest output
          cp -r $GITHUB_WORKSPACE/priv/static/images ./static/ 2>/dev/null || true
          cp $GITHUB_WORKSPACE/priv/static/favicon.ico ./static/ 2>/dev/null || true
          cp $GITHUB_WORKSPACE/priv/static/robots.txt ./static/ 2>/dev/null || true

          # List what we're uploading
          echo "Static files to upload:"
          ls -la ./static/

          # Remove any .DS_Store files before uploading
          find ./static -name ".DS_Store" -delete

          # Sync assets to S3 with appropriate cache headers
          # Fingerprinted assets get long cache (1 year)
          aws s3 sync ./static/assets s3://$ASSETS_BUCKET/assets \
            --cache-control "public, max-age=31536000, immutable" \
            --exclude ".DS_Store" \
            --delete

          # Other static files get shorter cache (1 day)
          aws s3 sync ./static s3://$ASSETS_BUCKET \
            --exclude "assets/*" \
            --exclude ".DS_Store" \
            --cache-control "public, max-age=86400" \
            --delete

      - name: Invalidate CloudFront cache
        env:
          CLOUDFRONT_ID: ${{ needs.deploy-infrastructure.outputs.cloudfront_id }}
        run: |
          aws cloudfront create-invalidation \
            --distribution-id $CLOUDFRONT_ID \
            --paths "/*"

  deploy-application:
    name: Deploy Application to EC2
    runs-on: ubuntu-latest
    needs: [build-and-push, deploy-infrastructure, upload-assets]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Run Database Migrations
        env:
          IMAGE: ${{ needs.build-and-push.outputs.image }}
        run: |
          # Get one instance to run migrations
          INSTANCE_ID=$(echo '${{ needs.deploy-infrastructure.outputs.ec2_ids }}' | jq -r '.[0]')
          echo "Running migrations on $INSTANCE_ID..."

          COMMAND_ID=$(aws ssm send-command \
            --instance-ids "$INSTANCE_ID" \
            --document-name "AWS-RunShellScript" \
            --parameters commands="[
              \"aws ecr get-login-password --region ${{ env.AWS_REGION }} | docker login --username AWS --password-stdin ${{ steps.login-ecr.outputs.registry }}\",
              \"docker pull ${{ needs.build-and-push.outputs.image }}\",
              \"printf 'DATABASE_URL=${{ secrets.DATABASE_URL }}\\nSECRET_KEY_BASE=${{ secrets.SECRET_KEY_BASE }}\\nPOOL_SIZE=2\\n' > /tmp/migrate.env\",
              \"docker run --rm --env-file /tmp/migrate.env ${{ needs.build-and-push.outputs.image }} /app/bin/hermes eval 'Hermes.Release.migrate()'\",
              \"rm /tmp/migrate.env\"
            ]" \
            --query 'Command.CommandId' \
            --output text)

          echo "Migration Command ID: $COMMAND_ID"

          # Wait for migrations to complete
          aws ssm wait command-executed \
            --command-id "$COMMAND_ID" \
            --instance-id "$INSTANCE_ID" || true

          STATUS=$(aws ssm get-command-invocation \
            --command-id "$COMMAND_ID" \
            --instance-id "$INSTANCE_ID" \
            --query 'Status' \
            --output text)

          echo "Migration status: $STATUS"

          if [ "$STATUS" != "Success" ]; then
            echo "Migration output:"
            aws ssm get-command-invocation \
              --command-id "$COMMAND_ID" \
              --instance-id "$INSTANCE_ID" \
              --query 'StandardOutputContent' \
              --output text
            echo "Migration errors:"
            aws ssm get-command-invocation \
              --command-id "$COMMAND_ID" \
              --instance-id "$INSTANCE_ID" \
              --query 'StandardErrorContent' \
              --output text
            exit 1
          fi

          echo "Migrations completed successfully"

      - name: Deploy to EC2 instances via SSM
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          IMAGE: ${{ needs.build-and-push.outputs.image }}
        run: |
          INSTANCE_IDS=$(echo '${{ needs.deploy-infrastructure.outputs.ec2_ids }}' | jq -r '.[]')

          for INSTANCE_ID in $INSTANCE_IDS; do
            echo "Deploying to $INSTANCE_ID..."

            # Send command via SSM
            COMMAND_ID=$(aws ssm send-command \
              --instance-ids "$INSTANCE_ID" \
              --document-name "AWS-RunShellScript" \
              --parameters commands="[
                \"aws ecr get-login-password --region ${{ env.AWS_REGION }} | docker login --username AWS --password-stdin ${{ steps.login-ecr.outputs.registry }}\",
                \"docker pull ${{ needs.build-and-push.outputs.image }}\",
                \"docker stop hermes || true\",
                \"docker rm hermes || true\",
                \"printf 'DATABASE_URL=${{ secrets.DATABASE_URL }}\\nSECRET_KEY_BASE=${{ secrets.SECRET_KEY_BASE }}\\nANTHROPIC_API_KEY=${{ secrets.ANTHROPIC_API_KEY }}\\nPHX_HOST=${{ secrets.PHX_HOST }}\\nSTATIC_URL=${{ needs.deploy-infrastructure.outputs.assets_url }}\\nPHX_SERVER=true\\nPORT=4000\\nMIX_ENV=prod\\nPOOL_SIZE=5\\n' > /opt/hermes/.env\",
                \"docker run -d --name hermes --restart unless-stopped -p 4000:4000 --env-file /opt/hermes/.env ${{ needs.build-and-push.outputs.image }}\",
                \"sleep 15\",
                \"docker logs hermes 2>&1 | tail -50 || true\",
                \"curl -f http://localhost:4000/health || (docker logs hermes 2>&1 | tail -100 && exit 1)\"
              ]" \
              --query 'Command.CommandId' \
              --output text)

            echo "Command ID: $COMMAND_ID"

            # Wait for command to complete
            aws ssm wait command-executed \
              --command-id "$COMMAND_ID" \
              --instance-id "$INSTANCE_ID" || true

            # Get command status
            STATUS=$(aws ssm get-command-invocation \
              --command-id "$COMMAND_ID" \
              --instance-id "$INSTANCE_ID" \
              --query 'Status' \
              --output text)

            echo "Command status: $STATUS"

            if [ "$STATUS" != "Success" ]; then
              echo "Command output:"
              aws ssm get-command-invocation \
                --command-id "$COMMAND_ID" \
                --instance-id "$INSTANCE_ID" \
                --query 'StandardOutputContent' \
                --output text
              echo "Command errors:"
              aws ssm get-command-invocation \
                --command-id "$COMMAND_ID" \
                --instance-id "$INSTANCE_ID" \
                --query 'StandardErrorContent' \
                --output text
              exit 1
            fi

            echo "Deployment to $INSTANCE_ID completed successfully"
          done

  notify:
    name: Notify Deployment Status
    runs-on: ubuntu-latest
    needs: [build-and-push, deploy-infrastructure, upload-assets, deploy-application]
    if: always()

    steps:
      - name: Deployment Status
        run: |
          if [ "${{ needs.deploy-application.result }}" == "success" ]; then
            echo "✅ Deployment succeeded!"
            echo "Image: ${{ needs.build-and-push.outputs.image }}"
          else
            echo "❌ Deployment failed!"
            exit 1
          fi
